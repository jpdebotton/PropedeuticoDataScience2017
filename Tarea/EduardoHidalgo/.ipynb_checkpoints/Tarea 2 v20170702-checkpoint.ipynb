{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2\n",
    "\n",
    "\n",
    "## 1) Teoría de Álgebra y Optimización\n",
    "\n",
    "# ¿Por qué una matriz equivale a una transformación lineal entre espacios vectoriales?\n",
    "\n",
    "Una transformación linea es una regla de correspondencia $\\mathbf T : \\mathbb{R}^m \\rightarrow \\mathbb{R}^n $ que cumple: </p>\n",
    "+ 1) $\\mathbf T(\\overrightarrow{x}+\\overrightarrow{y}) = T(\\overrightarrow{x}) + T(\\overrightarrow{y});$   $ \\forall \\overrightarrow{x},\\overrightarrow{y} \\in \\mathbb{R}^m  $ </p>\n",
    "+ 2) $T(\\alpha \\overrightarrow{x})=\\alpha T( \\overrightarrow{x})$ </p>\n",
    "<p>Por lo que si $\\mathbf A$ es una matriz de dimensiones $\\mathbf m\\times n$ y $\\overrightarrow{x}$ es un vector de de dimensiones $\\mathbf n\\times1$, entonces el vector definido por la transformacion  $\\mathbf A\\overrightarrow{x}=\\overrightarrow{y}$ será de dimensiones $\\mathbf m\\times1$ y cumplira con 1) y 2)</p>\n",
    "\n",
    "# ¿Cúal es el efecto de transformacion lineal de una matriz diagonal?;¿El de una ortogonal?\n",
    "\n",
    "+ 1) Las matrices diagonales redimensionan el \"volumen\" del espacio vectoriañ definido por el $\\mathbf span(\\overrightarrow{x})$</p>\n",
    "+ 2) Las matrices ortogonales son matrices de rotación (cuando su determinante es igual 1) o son matrices de reflexión (cuando su determinante es igal a -1). Estas cumplen con  $\\mathbf A  A^{T}=I \\Rightarrow A^{T}= A^{-1} $\n",
    "\n",
    "# ¿Qué es la descomposición en valores singulares de una matriz?\n",
    "\n",
    "<p>Es un resultado del álgebra que dice que para cualquier matriz $\\mathbf A \\in \\mathbb{R}_{m \\times n}$ existe una representacion de la misma como el producto de tres matrices:</p>\n",
    "\n",
    "- <p>$\\mathbf A = U\\Sigma V^{T}$ </p> \n",
    "<p>Donde $\\mathbf U,V^{T}$ son matrices ortogonales (o de rotación/reflexión) y $\\Sigma$ es una \"Semi\"-matriz diagonal (o de reescalamiento), por ejemplo</p>  \n",
    "+ <p>si $\\mathbf m = 3$ n $ $ y$ $ n = 6$: $\\begin{bmatrix}\n",
    " 1,  0,  0,  0,  0, 0 \\\\ \n",
    " 0,  1,  0,  0,  0, 0 \\\\ \n",
    " 0,  0,  1,  0,  0, 0 \n",
    "\\end{bmatrix}</p>  o \n",
    "+ <p>si $\\mathbf m = 6$ n $ $ y$ $ n = 3$: $\\begin{bmatrix}\n",
    " 1,  0,  0\\\\ \n",
    " 0,  1,  0\\\\ \n",
    " 0,  0,  1\\\\ \n",
    " 0,  0,  0\\\\ \n",
    " 0,  0,  0\\\\ \n",
    " 0,  0,  0  \n",
    "\\end{bmatrix} </p> \n",
    "\n",
    "# ¿Qué es diagonalizar una matriz?,¿Qué representan sus eigenvectores?\n",
    "\n",
    "+ 1) Es el caso simetrico de la descomposición en valores singulares (SVD). Y, dice que para cualquier matriz simetrica $\\mathbf A \\in \\mathbb{R}_{n \\times n}$ existe una representacion de la misma como el producto de tres matrices:</p>\n",
    "\n",
    "- <p>$\\mathbf A = W D W^{T}$ </p> \n",
    "<p>Donde $\\mathbf W$ es una matriz ortogonal (o de rotación/reflexión) y $D$ es una matriz diagonal (o de reescalamiento)</p>  \n",
    "+ 2) $\\lambda$ es un eigenvalor de $\\mathbf A$ y es el escalar asociado a la raís caracteristica del eigenvector $\\mathbf V$. Por lo que dado que $\\mathbf V$ es tal que: $\\mathbf AV =\\lambda V $ y  $\\mathbf AW =DW $ (por la representación diagonal). Entonces diagonalizar implica encontrar los eigenvectores y eigenvalores de  $\\mathbf A$</p>\n",
    "\n",
    "# ¿Cómo se interpreta la SVD como una composición de tres tipos de transformaciones lineales simples?\n",
    "\n",
    "<p>La SVD dice que: $ \\forall \\mathbf A \\in \\mathbb{R}_{m \\times n} \\exists \\mathbf A = U\\Sigma V^{T}$</p>\n",
    "<p>Donde $\\mathbf U,V^{T}$ son matrices ortogonales (o de rotación/reflexión) y $\\Sigma$ es una \"Semi\"-matriz diagonal (o de reescalamiento)</p>  \n",
    "\n",
    "# ¿Qué relacion hay entre la descomposición en valores singulares y la diagonalización?\n",
    "\n",
    "<p>La diagonalización es el caso, cuando $\\mathbf A$ es simétrica, de la SVD</p> \n",
    "\n",
    "# Describe el método de minimización por descenso gradiente\n",
    "\n",
    "<p>Es un método de aproximación numérico que se usa para encontrar los valores extremo de una función. El problema consiste en encontrar $\\overrightarrow{x}_{0}$ que minimizan/maximizan la función $F(\\overrightarrow{x})$. El algoritmo es el siguiente:</p> \n",
    "+ 1) Lanza una hipótesis razonable (que sea lo suficientemente cerca de un punto crítico) $\\overrightarrow{x}_{0}$\n",
    "+ 2) Encuenta $\\overrightarrow{x}_{0}$ deacuerdo a la siguiente ecuacion diferencial $\\overrightarrow{x}_{0} = \\overrightarrow{x}_{0} - \\alpha \\frac{\\partial \\mathbf F}{\\partial x}|_{\\overrightarrow{x}=\\overrightarrow{x}_{0}}$\n",
    "\n",
    "# Menciona 4 ejemplos de problemas de optimizacion (dos con restricciones y dos sin restricciones) que te parescan interesantes como Científico de Datos\n",
    "\n",
    "<p>Es más facil pensar en problemas con restricciones.</p> \n",
    "<p>Por lo que los primeros serán aquellos que ví varias veces durante la licenciatura: 1) Problema de Maximización de las ganacias 2) Problema de Maximización de la utilidad</p>\n",
    "+ 1) $\\mathbf max_{Q \\in \\mathbb{R}^+ }\\left \\{ P(Q)\\times Q  \\right \\} $ $\\mathbf t.q $ $ C(Q) \\leq  K$\n",
    "+ 2) $\\mathbf max_{\\overrightarrow{x} \\in \\mathbb{R}^n,\\overrightarrow{p} \\in \\mathbb{R}^n }\\left \\{ U(\\overrightarrow{x};\\overrightarrow{p}) \\right \\} $ $\\mathbf t.q $ $ I(\\overrightarrow{x};\\overrightarrow{p}) \\leq  M$\n",
    "<p>Y sus correspondientes problemas sin restricción serán las funciones lagrangianas que resultan (del teorema de la envolvente) al combinar la función objetivo con la condición correspondiente, así:</p>\n",
    "+ 1) $\\mathbf max_{Q \\in \\mathbb{R}^+,\\lambda \\in \\mathbb{R}}\\left \\{ \\mathscr{L}(Q,\\lambda) = P(Q)\\times Q - \\lambda(K - C(Q)) \\right \\} $\n",
    "+ 2) $\\mathbf max_{\\overrightarrow{x} \\in \\mathbb{R}^n,\\overrightarrow{p} \\in \\mathbb{R}^n}\\left \\{ \\mathscr{L}(\\overrightarrow{x}(\\overrightarrow{p}),\\lambda) = U(\\overrightarrow{x})- \\lambda(M - I(\\overrightarrow{x})) \\right \\} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
